---
layout: page
title: "Publications"
tagline : ""
use_math: true
lang: en
---
{% include JB/setup %}

{% assign posts_collate = site.categories.projects %}
{% include JB/posts_collate %}

<link rel="stylesheet" href="/glyphicons/css/glyphicons.css">

<table style="width:100%">
<col width="90%">
<col width="10">
<col >

<!-- <tr height="50">
<td style="padding-left: 1px;
    padding-bottom: 3px;
    vertical-align: bottom;">
    <strong style="font-size: 25px;">2017</strong></td>
</tr> -->

<!-- <tr style="border-bottom:1pt solid #eee" >
<td markdown="1">
![videovec](/img/main/videovec.jpg){:class="img-shadow"}
</td>
<td></td>
<td markdown="1">
<div><a href="/archive/research/videovec/"><b>Video Vectorization via Tetrahedral Remeshing</b></a></div>
<div><b>Chuan Wang</b>, Jie Zhu, Yanwen Guo, Wenping Wang</div>
<div><i>IEEE Transactions on Image Processing, 2017</i></div>
<div><i>"converting a raster video into its vectorized version, with perservation of the video features"</i></div>

|| <em class="icon-home"></em> || [project page](/archive/research/videovec/) || <em class="icon-file"></em> || [paper](/archive/research/videovec/paper.pdf) || <em class="icon-film"></em> || [video demo](https://youtu.be/KmPdjB8f4ww) ||

</td> 
</tr> -->

<tr height="50">
<td style="padding-left: 1px;
    padding-bottom: 3px;
    vertical-align: bottom;">
    <strong style="font-size: 25px;">2024</strong></td>
</tr>

<tr style="border-bottom:1pt solid #eee" >
<td markdown="1">
<div><b>Performant ASR Models for Medical Entities in Accented Speech</b></div>
<div>
Afonja, T., Olatunji, T., Ogun, S., Etori, N. A., Owodunni, A., & Yekini, M. (2024). Performant ASR Models for Medical Entities in Accented Speech. Interspeech 2024.</div>
|| <em class="icon-home"/> || [paper](https://arxiv.org/abs/2406.12387) || <em class="icon-github"/> || [model link](https://huggingface.co/intronhealth/afrispeech-whisper-medium-all) ||
</td>
</tr>

<tr style="border-bottom:1pt solid #eee" >
<td markdown="1">
<div><b>1000 African Voices: Advancing inclusive multi-speaker multi-accent speech synthesis</b></div>
<div>
Ogun, S., Owodunni, A. T., Olatunji, T., Alese, E., Oladimeji, B., Afonja, T., ... & Adewumi, T. (2024). 1000 African Voices: Advancing inclusive multi-speaker multi-accent speech synthesis. Interspeech 2024.</div>
|| <em class="icon-home"/> || [paper](https://arxiv.org/abs/2406.11727) || <em class="icon-github"/> || [model link](https://huggingface.co/intronhealth/afro-tts) ||
</td>
</tr>

<tr style="border-bottom:1pt solid #eee" >
<td markdown="1">
<div><b>STATE OF THE ART. THINK BEFORE LOADING.</b></div>
<div>
Guillaume Coiﬀier, Sewade Ogun, Leo Valque, Priyansh Trivedi. STATE OF THE ART. THINK BEFORE LOADING, 2024, 978-2-9591975-0-5. ￿hal-04509255￿</div>
|| <em class="icon-home"/> || [paper](https://hal.univ-lorraine.fr/hal-04509255v1/document) ||
</td>
</tr>

<tr height="50">
<td style="padding-left: 1px;
    padding-bottom: 3px;
    vertical-align: bottom;">
    <strong style="font-size: 25px;">2023</strong></td>
</tr>

<tr style="border-bottom:1pt solid #eee" >
<!-- <td markdown="1">
![spiden](/img/main/masakhane_paper_1.png){:class="img-shadow"}
</td>
<td></td> -->
<td markdown="1">
<div><b>Stochastic Pitch Prediction Improves the Diversity and Naturalness of Speech in Glow-TTS.</b></div>
<div>
Ogun, S., Colotte, V., Vincent, E. (2023) Stochastic Pitch Prediction Improves the Diversity and Naturalness of Speech in Glow-TTS. Proc. INTERSPEECH 2023, 4878-4882, doi: 10.21437/Interspeech.2023-1673</div>
|| <em class="icon-home"/> || [paper](https://arxiv.org/abs/2305.17724) || <em class="icon-github"/> || [source code](https://github.com/ogunlao/glowtts_stdp) ||
</td>
</tr>

<tr style="border-bottom:1pt solid #eee" >
<td markdown="1">
<div><b>Can we use Common Voice to train a Multi-Speaker TTS system?</b></div>
<div>
Ogun, S., Colotte, V., & Vincent, E. (2023, January). Can we use Common Voice to train a Multi-Speaker TTS system?. In 2022 IEEE Spoken Language Technology Workshop (SLT) (pp. 900-905). IEEE.</div>
|| <em class="icon-home"/> || [paper](https://arxiv.org/abs/2210.06370) || <em class="icon-github"/> || [Dataset link](https://github.com/ogunlao/glowtts_stdp/tree/main/dataset) ||
</td>
</tr>

<!-- <tr height="50">
<td style="padding-left: 1px;
    padding-bottom: 3px;
    vertical-align: bottom;">
    <strong style="font-size: 25px;">2015</strong></td>
</tr> -->

<!-- <tr style="border-bottom:1pt solid #eee" >
<td markdown="1">
![thesis](/img/main/hkulogo2.jpg){:class="img-shadow"}
</td>
<td></td>
<td markdown="1">
<div><b>Ph.D Thesis: Video Object Co-Segmentation and Video Vectorization</b></div>
<div><b>Chuan Wang</b></div>
<div><i>The University of Hong Kong, January 2015.</i></div>
<div><i>"a detailed version of the works in video object co-segmentation and video vectorization"</i></div>

|| <em class="icon-file"></em> || thesis || <!--[thesis](/archive/research/thesis.pdf)-->

<!-- </td> 
</tr> -->

<!-- <tr height="50">
<td style="padding-left: 1px;
    padding-bottom: 3px;
    vertical-align: bottom;">
    <strong style="font-size: 25px;">2014</strong></td>
</tr> -->

<!-- <tr style="border-bottom:1pt solid #eee" >
<td markdown="1">
![videocoseg](/img/main/videocoseg.jpg){:class="img-shadow"}
</td>
<td></td>
<td markdown="1">
<div><a href="/archive/research/videocoseg/"><b>Video Object Co-segmentation via Subspace Clustering and Quadratic Pseudo-Boolean Optimization in an MRF Framework</b></a></div>
<div><b>Chuan Wang</b>, Yanwen Guo, Jie Zhu, Linbo Wang, Wenping Wang</div>
<div><i>IEEE Transactions on Multimedia, 2014.</i></div>
<div><i>"common-foreground co-segmentation system for a group of videos"</i></div>

|| <em class="icon-home"/> || [project page](/archive/research/videocoseg/) || <em class="icon-file"/> || [paper](/archive/research/videocoseg/paper.pdf) || <em class="icon-film"/> || [video demo](https://youtu.be/vbeN6JMkuGk) ||

</td> 
</tr> -->

</table>

<style type="text/css">
td {
    border: 0.5px;
    vertical-align: center;
    text-align: left;
}
</style>
